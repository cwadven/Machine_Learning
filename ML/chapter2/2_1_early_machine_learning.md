## 인공 뉴런 : 초기 머신러닝의 간단한 역사

**초창기 머신러닝 알고리즘**

~~~
퍼셉트론
적응형 선형 뉴런
~~~

> **퍼셉트론**
MCP 뉴런과 로젠블라트의 임계 퍼셉트론 모델 이면에 있는 전반적인 아이디어는 뇌의 뉴런 하나가 작동하는 방식을 흉내 내려는 환원주의 접근 방식을 사용한 것이다.

### 퍼셉트론 구축 방법 설명 👨‍💻

한 행의 각각의(속성) 입력값 `x`

<img src="https://latex.codecogs.com/svg.latex?x_{i}" title="x_{i}" /><br>
0과 1사이의 값으로 설정 (비율로)

`y` : 라벨은 -1 혹은 1로 변환 시켜준다. (추후, 임계함수를 통해)

`학습률`을 작은 값 중에 초기화 시킨다. 예) 0.01

입력값이 n개 일 경우 세타를 위해서 입력값을 n+1개로 하고, 추가된 즉 x0은 1로 한다.

<img src="https://latex.codecogs.com/svg.latex?x_{0}=1" title="x_{0}=1" /><br>

그래서 초기에 가중치들 w0, w1, ... ,wn 개를 랜덤으로 초기화 시키는데, 0과 가깝지만 0이 아닌 수로 초기화 시킨다.

<img src="https://latex.codecogs.com/svg.latex?w_{0}=-0.3w_{1}=-0.3w_{2}=0.1w_{n}=0.8" title="w_{0}=-0.3w_{1}=-0.3w_{2}=0.1w_{n}=0.8" /><br>

초기화를 시켰으니 z를 구할 수 있다.

z = w0x0 + w1x1 + w2x2 ... wnxn --> - ~ 0 ~ +

<img src="https://latex.codecogs.com/svg.latex?z=w_{0}x_{0}+w_{1}x_{1}+w_{2}x_{2}+w_{n}x_{n}" title="z=w_{0}x_{0}+w_{1}x_{1}+w_{2}x_{2}+w_{n}x_{n}" /><br>


z를 임계 함수를 통해 Z가 0 보다 작으면 -1, 0 보다 크면 1로 컴퓨터 해당 -1 혹은 1로 예측한 값이 나온다.

<img src="https://github.com/cwadven/Machine_Learning/blob/master/ML/chapter2/img/function.PNG" alt="drawing" width="600"/><br>

컴퓨터가 예측을 했기 때문에 `학습률*(오차)*각입력값`를 하여 결과는 각각의 `x`에 대한 `변화한 w(△w)`값이 된다.<br>
`오차 = 실제값 - 예측한값`

~~~
학습률 : 0.01, 컴퓨터가 예측 : -1, 실제 값 : 1, 입력값 x0 = 1, x1 = 0.2, x2 = 0.4, x3 = 0.8

예) 
0.01 * (-1-1) * 1 = △w0
0.01 * (-1-1) * 0.2 = △w1
0.01 * (-1-1) * 0.4 = △w2
0.01 * (-1-1) * 0.8 = △w3

이전 w0 + △w0 = 새로운 w0
이전 w1 + △w1 = 새로운 w1
이전 w2 + △w2 = 새로운 w2
이전 w3 + △w3 = 새로운 w3

z = w0x1 + w1x1 + w2x2 + w3x3

z 가 만약 0.0 보다 크면 1, 0.0 보다 작으면 -1로 또 예측
~~~

그래서 그 `변화한 w값(△w)`을 이전 `w`값에 더한다.

이걸 epoch 만큼 반복 한다.